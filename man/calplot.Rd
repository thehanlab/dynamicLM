% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/calplot.R
\name{calplot}
\alias{calplot}
\title{Calibration plots for dynamic risk prediction landmark models.}
\usage{
calplot(
  object,
  times,
  formula,
  data,
  lms,
  id_col = "ID",
  split.method = "none",
  B = 1,
  M,
  cores = 1,
  seed,
  regression_values = FALSE,
  cause,
  plot = TRUE,
  main,
  ...
)
}
\arguments{
\item{object}{A named list of prediction models, where allowed entries are
outputs from \code{\link[=predict.dynamicLM]{predict.dynamicLM()}} or supermodels from \code{\link[=dynamic_lm]{dynamic_lm()}}
depending on the type of calibration.}

\item{times}{Landmark times for which calibration must be plot. These must be
a subset of landmark times used during the prediction}

\item{formula}{A survival or event history formula (\code{Hist(...)}). The left
If none is given, it is obtained from the prediction object.}

\item{data}{Data for external validation. This can be an object of class
LMdataframe (i.e., created by calling \code{\link[=stack_data]{stack_data()}} and
\code{\link[=add_interactions]{add_interactions()}}), or a data.frame. If it is a data.frame, argument
\code{lms} must be specified.}

\item{lms}{Landmark times corresponding to the patient entries in data. Only
required if \code{data} is specified and is a dataframe.
\code{lms} can be a string (indicating a column in data), a vector of length
nrow(data), or a single value if all patient entries were obtained at the
same landmark time.}

\item{id_col}{Column name that identifies individuals in data. If omitted, it
is obtained from the prediction object.}

\item{split.method}{Defines the internal validation design as in
\code{\link[pec:calPlot]{pec::calPlot()}}. Options are currently "none" or "bootcv".

"none": assess the model in the test data (\code{data} argument)/data it was

"bootcv": \code{B} models are trained on bootstrap samples either drawn with
size \code{M}. Models are then assessed in observations not in the sample.}

\item{B}{Number of times bootstrapping is performed.}

\item{M}{Subsample size for training in cross-validation. Entries not sampled}

\item{cores}{To perform parallel computing, specifies the number of cores.
(Not yet implemented)}

\item{seed}{Optional, integer passed to set.seed. If not given or NA, no seed}

\item{regression_values}{Default is FALSE. If set to TRUE, the returned list
is appended by another list \code{regression_values},
which contains the intercept and slope of a linear regression of each model
for each landmark time (i.e., each calibration plot).
Note that perfect calibration has a slope of 1 and an intercept of 0.}

\item{cause}{Cause of interest if considering competing risks. If left blank,
this is inferred from object.}

\item{plot}{If FALSE, do not plot the results, just return a plottable
object. Default is TRUE.}

\item{main}{Optional title to override default.}

\item{...}{Additional arguments to pass to calPlot (\code{pec} package).
These arguments have been included for user flexibility but have not been
tested and should be used with precaution.}
}
\value{
List of plots of w-year risk, one entry per prediction/landmark time
point. List has a component \verb{$regression_values} (if argument
regression_values is set to TRUE) which is a list of which contains the
intercept and slope of a linear regression of each model
for each landmark time (i.e., each calibration plot).
}
\description{
There are three ways to perform calibration: apparent/internal, bootstrapped,
and external. Accordingly, the named list of prediction models must be as
follows:
\itemize{
\item For both apparent/internal calbration, objects output from
\code{\link[=predict.dynamicLM]{predict.dynamicLM()}} for supermodels fit with \code{\link[=dynamic_lm]{dynamic_lm()}} may be used
as input.
\item In order to bootstrap, supermodels fit with \code{\link[=dynamic_lm]{dynamic_lm()}} may be used as
input (note that the argument \code{x=TRUE} must be specified when fitting the
model in \code{\link[=dynamic_lm]{dynamic_lm()}}).
\item For external calibration, supermodels fit with \code{\link[=dynamic_lm]{dynamic_lm()}} are input
along with new data in the \code{data} argument. This data can be a LMdataframe
or a dataframe (in which case \code{lms} must be specified).
}
}
\details{
For both internal calibration and bootstrapping, it is assumed that all
models in \code{object} are fit on the same data.

When collecting bootstrap samples, the same individuals are
considered across landmarks.
I.e., sample \code{M} unique individuals, train on the super dataset formed by
these individuals, and validate on the individuals not sampled at the
landmarks they remain alive (or that are given in \code{times}).

Note that only complete cases of data are considered (whatever type of
calibration is performed).

A comment on the following message:
"Dropping bootstrap b = {X} for model {name} due
to unreliable predictions". As certain approximations are made, numerical
overflow sometimes occurs in predictions for bootstrapped samples. To avoid
potential errors, the whole bootstrap sample is dropped in this case. Note
that input data should be complete otherwise this may occur
unintentionally. Calibration plots are still produced excluding predictions
made during the bootstrap resampling.
}
\examples{
\dontrun{
# Internal validation
par(mfrow = c(2, 2), pty = "s")
outlist <- calplot(list("Model1" = supermodel),
                   method = "quantile", q = 5,  # method for calibration plot
                   regression_values = TRUE,    # output regression values
                   ylim = c(0, 0.4), xlim = c(0, 0.4)) # optional
outlist$regression_values

# Bootstrapping
# Remember to fit the supermodel with argument 'x = TRUE'
par(mfrow = c(2, 2), pty = "s")
outlist <- calplot(list("Model1" = supermodel),
                   method = "quantile", q = 5,
                   split.method = "bootcv", B = 10, # 10 bootstraps
                   ylim = c(0, 0.4), xlim = c(0, 0.4))

# External validation
# a) newdata is a dataframe
newdata <- relapse[relapse$T_txgiven == 0, ]
newdata$age <- newdata$age.at.time.0
newdata$LM <- 0
par(mfrow = c(1, 1))
cal <- calplot(list("Model1" = supermodel), data = newdata, lms = "LM",
               method = "quantile", q = 5, ylim = c(0, 0.1), xlim = c(0, 0.1))

# b) newdata is a landmark dataset
par(mfrow = c(2, 2), pty = "s")
lmdata_new <- lmdata
cal <- calplot(list("Model1" = supermodel), data = lmdata_new,
               method = "quantile", q = 10, ylim = c(0, 0.4), xlim = c(0, 0.4))
}
}
\seealso{
\code{\link[=score]{score()}}, \code{\link[pec:calPlot]{pec::calPlot()}}
}
